What we need to do is create a server where our code is written, and if anyone sends a request there, we reply back to that request.1

The command "npm init" is used to initialize an application with the Node Package Manager. 

dotenv -> for environment variables

import->modular.js // isko use karne ke liye package.json me type:module.js karna hoga , ye async hota hai
require->common.js

axios:
Axios is a promise-based HTTP client for JavaScript (works in browser and Node.js).

ðŸ”¹ What it's used for:
To send HTTP requests (GET, POST, PUT, DELETE, etc.) from your frontend to servers/APIs.

Axios is similar to fetch, but with additional features like automatic JSON parsing, request/response interceptors, better error handling, and simpler syntax for some common tasks.

Using /api/ in URLs like http://localhost:3000/api/something is a common convention, especially in web development projects that separate frontend and backend logic.

 Why Use /api/ in URL Paths
ðŸ”¹ 1. Semantic Clarity
Using /api/ makes it clear that this route is an API endpoint, not a frontend page.

/about â†’ your frontend page

/api/users â†’ backend endpoint for fetching user data

This separation helps keep routes organized.

ðŸ”¹ 2. Avoids Route Conflicts
If your app has both frontend routes and backend routes served from the same server (e.g., in Express or Next.js), using /api/ prevents naming collisions.

Example:

/login â†’ React frontend login page

/api/login â†’ backend POST handler for user authentication

ðŸ”¹ 3. Proxy Configuration (e.g., in React)
In development, when using Create React App and a proxy is set in package.json:
"proxy": "http://localhost:5000"
You can send requests to /api/... and they get forwarded to your backend server running on port 5000.

So in frontend:
axios.get('/api/data')
â†’ goes to http://localhost:5000/api/data under the hood.

ðŸ”¹ 4. Deployment Best Practices
When deploying full-stack apps (e.g., with Vercel, Netlify, or Nginx):

Frontend assets serve from /

Backend endpoints serve from /api/...

This keeps the architecture modular and scalable.


2. CORS (Cross-Origin Resource Sharing)
ðŸ”¹ What it is:
A security mechanism enforced by browsers to prevent a frontend (e.g., http://localhost:3000) from making requests to a different origin (e.g., https://api.example.com) unless the server allows it.

ðŸ”¹ Problem:
If CORS is not enabled on the server, you'll get this browser error:

Access to XMLHttpRequest at 'https://api.example.com' from origin 'http://localhost:3000' has been blocked by CORS policy.
ðŸ”¹ Fix (from the backend side):
The backend must set this header in its response:

Access-Control-Allow-Origin: *
or a specific domain:

Access-Control-Allow-Origin: http://localhost:3000

âœ… 3. Proxy (Frontend Dev Solution to CORS)
When you don't control the backend, you can bypass CORS during development by setting up a proxy.

ðŸ”¹ Example (React + CRA):
In package.json:
"proxy": "https://api.example.com"
Then, in Axios:
axios.get('/data'); // automatically sent to https://api.example.com/data
The development server (like Webpack Dev Server) proxies the request, so the browser thinks it's same-origin and CORS doesn't trigger.

->>>> NOT A GOOD PRACTICE
let's understand the why behind building a Vite app into a .dist folder and serving it from your backend.
This setup is about deploying a full-stack web app with:

A frontend (React/Vite)

A backend (e.g., Node.js/Express)

You're combining the two so they run on a single server â€” simplifying hosting and deployment.

Single deployment target	You only need to deploy your backend (e.g., to Heroku, Render, Railway, etc.) and it will also serve your frontend.
Backend handles both API and UI	You can fetch /api/* from the backend and load React UI from the same server.
No CORS hassle in production	Because both frontend and backend are served from the same origin, you avoid CORS issues.
Simplified dev/prod transition	During development, you use Vite + proxy. In production, your backend serves everything.

Scenario	Why Not Ideal
You host frontend and backend separately->	If your backend is on a subdomain or microservice (e.g., API on api.example.com and UI on app.example.com), youâ€™ll deploy each separately.
Using serverless backend (like Firebase/Netlify Functions)->	These donâ€™t support serving static frontend files from backend routes directly.
Frontend hosted on a CDN (e.g., Vercel, Netlify)->	Then your React/Vite build should go to the CDN. Backend serves only APIs.
Want CI/CD separation->	Sometimes teams want different pipelines for frontend and backend, so combining them complicates deployments.

//mongoose

âœ… 1. Import and Connect
const mongoose = require('mongoose');
mongoose.connect('mongodb://localhost:27017/mydb'); // or use your MongoDB URI
âœ… 2. Define a Schema
const userSchema = new mongoose.Schema({
  name: String,
  age: Number
});
âœ… 3. Create a Model
const User = mongoose.model('User', userSchema);

// database me small letter with s like users ho jata hai

Common Field Options in Mongoose
Option	Description
type-> Defines the data type (String, Number, Date, Boolean, ObjectId, etc.)
required->	Makes the field mandatory
unique->	Ensures unique values in the DB (via MongoDB index)
lowercase->	Converts string to lowercase
uppercase->	Converts string to uppercase
default->	Sets a default value if none is provided
trim->	Removes leading/trailing whitespace
min / max	-> Validates numeric range (or string length in arrays)
match->	Validates strings using a RegExp pattern
enum->	Limits value to a set of allowed options
validate->	Allows custom validation logic

const userSchema = new mongoose.Schema({
  username: {
    type: String,
    required: true,
    unique: true,
    lowercase: true,
    trim: true,
    minlength: 3,
    maxlength: 20
  },
  email: {
    type: String,
    required: true,
    unique: true,
    lowercase: true,
    match: /^[\w-\.]+@([\w-]+\.)+[\w-]{2,4}$/
  },
  role: {
    type: String,
    enum: ['user', 'admin', 'moderator'],
    default: 'user'
  },
  age: {
    type: Number,
    min: 13,
    max: 120,
    default: 18
  },
  createdAt: {
    type: Date,
    default: Date.now
  },
  password: {
    type: String,
    required: true,
    validate: {
      validator: (v) => v.length >= 6,
      message: 'Password must be at least 6 characters.'
    }
  }
});

const userSchema = new mongoose.Schema({
  name: {
    type: String,
    required: [true, 'Name is required']
  },
  email: {
    type: String,
    required: [true, 'Email is required']
  }
}, {
  timestamps: true
});
This will automatically include:

createdAt: when the document was first saved

updatedAt: when the document was last modified

{
  "_id": "64f4dfed3a...f9",
  "name": "Alice",
  "email": "alice@example.com",
  "createdAt": "2025-07-27T08:22:00.000Z",
  "updatedAt": "2025-07-27T08:22:00.000Z"
}

const mongoose = require('mongoose');
const Schema = mongoose.Schema;

const todoSchema = new Schema({
  title: {
    type: String,
    required: [true, 'Title is required']
  },
  completed: {
    type: Boolean,
    default: false
  },
  createdBy: {
    type: Schema.Types.ObjectId,
    ref: 'User',
    required: true
  },
  subTodos: [{
    title: {
      type: String,
      required: true
    },
    completed: {
      type: Boolean,
      default: false
    }
  }]
}, {
  timestamps: true
});


âœ… Storing Images in MongoDB: Pros & Cons
Yes, MongoDB can store images as binary data (using Buffer type), usually in a field like:

js
Copy
Edit
image: {
  data: Buffer,
  contentType: String
}
But this method has drawbacks:

âŒ Issues:
MongoDB documents have a 16 MB limit

Makes DB bloated and slower for queries/replication

Uploading/downloading images becomes heavy

âœ… Better Alternatives for Image Storage
1. Use Third-Party Services
Use platforms like:

Cloudinary

Amazon S3

Firebase Storage

Imgur (for small projects)

ðŸ”— You upload the image to these services and just store the URL in MongoDB:

imageUrl: "https://res.cloudinary.com/yourimg.jpg"

âœ… What Are "Mini Models" (Subschemas)?
They are Mongoose schemas used inside other schemas, typically for:

Arrays of structured data

Embedded, reusable schema blocks

Better type safety

const mongoose = require('mongoose');
const Schema = mongoose.Schema;

// ðŸŸ¢ Mini model: SubTodo (not a full collection)
const subTodoSchema = new Schema({
  title: { type: String, required: true },
  completed: { type: Boolean, default: false }
});

// ðŸ”µ Main model: Todo
const todoSchema = new Schema({
  title: { type: String, required: true },
  createdBy: { type: Schema.Types.ObjectId, ref: 'User' },
  subTodos: [subTodoSchema] // ðŸ‘ˆ Embedded mini model
}, {
  timestamps: true
});

const Todo = mongoose.model('Todo', todoSchema);

âœ… enum in Mongoose
In Mongoose, enum is used to restrict a field to a set of predefined values â€” like a dropdown or radio button in frontend forms.
const userSchema = new mongoose.Schema({
  role: {
    type: String,
    enum: ['admin', 'user', 'moderator'],
    required: true
  }
});


The complete process of initializing a Node.js project, setting up Git, and pushing it to GitHub. Here's the clean step-by-step guide with the exact commands:

Initialize Node.js Project
npm init -y
This creates a package.json file with default values.
 Create a README
git init
git add .
git commit -m "Initial commit"
git branch -M main
Go to GitHub â†’ New Repository â†’ Name it (e.g., my-project) â†’ Do not initialize with README â†’ Create repo.

You will get a remote URL, like:
https://github.com/yourusername/my-project.git

git remote add origin https://github.com/yourusername/my-project.git
git push -u origin main

âœ… .gitkeep â€” Used to Track Empty Folders in Git
ðŸ”¹ Why Itâ€™s Needed:
Git doesnâ€™t track empty folders.

So, if you create a folder like logs/ or uploads/, and it's empty â€” Git will ignore it.


.gitignore â€” Ignore Files & Folders in Git
.gitignore tells Git what NOT to track â€” like temporary files, secrets, or folders like node_modules/.


->nodemon â€” Auto-Restart Node.js on File Changes
nodemon is a development tool that automatically restarts your Node.js app when you make changes to source files. It's extremely useful for backend development.


ðŸ”¹ What is Prettier?
Prettier is an opinionated code formatter that:

Automatically formats your code

Enforces consistent style (indentation, quotes, semicolons, etc.)

Saves time and avoids debates over formatting

Works with JavaScript, TypeScript, HTML, CSS, JSON, Markdown, etc.

You're absolutely right â€” MongoDB should NOT allow access from all IPs (0.0.0.0/0) in production, as it poses a critical security risk.

ðŸ”´ Why "Allow Access from Anywhere" (0.0.0.0/0) is Dangerous
It exposes your MongoDB instance to anyone on the internet.

Bots can scan for open ports (like 27017) and attempt brute-force attacks.

Misconfigured or leaked credentials can lead to data theft or destruction.


you should always connect to your database using async/await with try/catch, especially in production-ready Node.js applications.

âœ… Why Use async/await with try/catch?
Feature	Why It Matters
âœ… async/await	Makes your code cleaner and more readable (avoids .then())
âœ… try/catch	Handles errors properly â€” avoids app crashing on DB failure
âœ… Production-safe	Lets you retry, log, or shut down gracefully if DB fails

âœ… 1. Async IIFE (Immediately Invoked Function Expression)
js
Copy
Edit
;(async () => {
  try {
    await someAsyncTask();
    console.log('IIFE Done');
  } catch (err) {
    console.error(err);
  }
})();
ðŸ”¹ Key Features:
Self-executing: runs as soon as itâ€™s defined

No need to call it separately

Used when you want to execute top-level async logic immediately

âœ… 2. Normal Async Function
async function initApp() {
  try {
    await someAsyncTask();
    console.log('Normal Function Done');
  } catch (err) {
    console.error(err);
  }
}

initApp(); // You must call it explicitly
ðŸ”¹ Key Features:
Can be reused (called multiple times)

Can be named and exported/imported

More suited for modular and scalable apps

// agar .env me change kiya tu nodemon kuch nhi kar bayega you have to restart

Who Catches It	When It Happens
catch block	Errors that occur inside the try block before the app.listen() starts
app.on("error") handler	Errors that happen after the server is running, like a server crash or port conflict

cookie-parser
ðŸ”¸ What is it?
Middleware to parse cookies sent by the client (browser).
Cookies are stored in req.headers.cookie, but thatâ€™s a raw string â€” cookie-parser makes it easy to read.

ðŸ”¸ Why use it?
If your app uses:

Sessions

JWT tokens stored in cookies

User authentication using cookies


ðŸ”¶ What is cors?
cors is a middleware in Express that tells the server:
âž¡ï¸ "Hey! It's okay to accept requests from another domain/origin."

Normally, browsers block cross-origin requests (security reasons).
This middleware adds HTTP headers to tell the browser:
âœ… "Yes, I trust this other origin. Let it talk to me."

ðŸ”¶ Breaking it Down:
1ï¸âƒ£ app.use(cors({...}))
You're using the cors() middleware globally on your Express app.
This means: for all routes, the CORS settings apply.

2ï¸âƒ£ origin: process.env.CORS_ORIGIN
This sets who (which frontend) is allowed to make requests.

process.env.CORS_ORIGIN typically points to your frontend domain.

ðŸ”¹ For example:
CORS_ORIGIN=http://localhost:5173
This will allow your backend (say running on localhost:5000) to accept requests from Vite frontend on localhost:5173.

3.credentials: true
This is very important if:

You are sending cookies

Or using Authorization headers

Or doing any kind of session/login work

When credentials: true is enabled:

The server will allow the browser to send cookies (like JWT tokens).

CORS response will include: Access-Control-Allow-Credentials: true

But there's a catch...

âž¡ï¸ If credentials: true, you must specify a specific origin.
You cannot set origin: "*", or browser will reject it.

app.use(express.json({ limit: "16kb" }))
âœ… What it does:
This middleware parses incoming JSON data from the request body.

Adds it to req.body.

ðŸ“¦ Why limit: "16kb"?
It restricts the max size of incoming JSON payloads to 16 kilobytes.

This helps prevent abuse (like someone sending a 5MB JSON body to crash your server).


app.use(express.urlencoded({ extended: true }))
âœ… What it does:
Parses form data (i.e., from application/x-www-form-urlencoded requests, like from HTML forms).

Adds it to req.body.

ðŸ” What does extended: true mean?
It tells Express to use the qs library instead of the built-in querystring library.

This allows nested objects in form data (like user[name]=Arnav).

ðŸ§  Use Case:
When someone submits an HTML form using POST method (not JSON), this parses the data.

app.use(express.static("public"))
âœ… What it does:
Serves static files (HTML, CSS, JS, images, PDFs, etc.) from the public folder.

If someone accesses http://localhost:5000/logo.png, it looks inside public/logo.png.

app.use(cookieParser())
âœ… What it does:
Parses the Cookie header from incoming requests.

Converts cookies into a nice JavaScript object: req.cookies.

ðŸª Why use it?
Helpful for authentication, sessions, tracking user state, etc.

If you're storing JWTs in cookies, this is essential.

->>>>
const asynchandler = (requestHandler) => {
    return (req, res, next) => {
        Promise.resolve(requestHandler(req, res, next)).catch((err) => next(err))
    }
}

ðŸ”¹ Purpose:
This function wraps your route handlers, especially those using async/await, and automatically catches any errors â€” so you don't have to write try/catch in every route.

app.get('/data', async (req, res) => {
  const data = await fetchFromDatabase(); // If this fails, Express wonâ€™t catch it!
  res.send(data);
});
If fetchFromDatabase() throws an error, Express will not know, because await errors don't auto-trigger Express's next(err) system.

const asyncHandler = (requestHandler) => {
  return (req, res, next) => {
    Promise.resolve(requestHandler(req, res, next)).catch(next);
  };
};
ðŸ’¡ What it's doing:
Takes your async (req, res) function.

Runs it and wraps it in Promise.resolve(...)

If that function throws an error (rejects), it automatically .catch()es it and calls next(err).

const asyncHandler = (requestHandler) => async (req, res, next) => {
  try {
    await requestHandler(req, res, next);
  } catch (error) {
    res.status(error.code || 500).json({
      success: false,
      message: error.message
    });
  }
};
This is a higher-order function â€” a function that returns another function.

Its job is to wrap your async controller functions and handle errors gracefully without crashing the app.


creating a custom error class that extends the built-in Error class in JavaScript.

This means it inherits all behavior of a normal error but adds custom properties, like statusCode, errors, etc., which are useful in APIs.

ðŸ§  Why not just use throw new Error()?
Error only gives you a message and stack.

But in APIs, you want to send:

statusCode (e.g., 404, 500)

success: false

data: null

errors: [ ...details ]

So ApiError helps you define that in one place.


class ApiResponse {
    constructor(statusCode, data, message = "Success") {
        this.statusCode = statusCode;
        this.data = data;
        this.message = message;
        this.success = statusCode < 400;
    }
}
It builds a standard API response object. When you send data to the frontend/client, this helps maintain a consistent structure for all successful responses.


What is BSON?
MongoDB does not store data in JSON.

It stores data in BSON â€” Binary JSON.

BSON = Binary + JSON + extra types

It allows extra data types that JSON doesnâ€™t support, like:

ObjectId

Date

Binary

Decimal128

So while you read and write in JSON, MongoDB stores in BSON for performance and rich data types.

hat is mongoose-aggregate-paginate-v2?
mongoose-aggregate-paginate-v2 is a Mongoose plugin that helps you easily paginate aggregation results.

ðŸ’¡ Normally, when you use .aggregate(), you have to manually handle:

skip

limit

total count

current page

total pages

This plugin automates all that.


ðŸ” JWT is a Bearer Token
âœ… JWT (JSON Web Token) is commonly used as a bearer token for authentication and authorization in APIs.
ðŸ“¦ What is a Bearer Token?
A Bearer Token is a type of token that is sent in the Authorization header of an HTTP request to access protected routes.


Summary:
Feature	bcrypt	JWT
Purpose	Password security	Session & identity
Where	Before saving/verifying user	After verifying user
Data stored	Encrypted password	Encrypted user info
Used for	Password checking	User login/token-based auth


 What is multer?
multer is a Node.js middleware for handling multipart/form-data, which is primarily used for uploading files.

const storage = multer.diskStorage({
    destination: function (req, file, cb) {
        cb(null, './uploads/');
    },
    filename: function (req, file, cb) {
        cb(null, file.fieldname + '-' + Date.now() + '-' + file.originalname);
    }
});
âž¤ destination:
Tells multer where to store uploaded files.

In this case: stores all files in a folder called uploads/ in your root directory.

âž¤ filename:
Tells multer how to name uploaded files.

Here, the file name will look like:
avatar-1690923600000-myphoto.jpg
(where avatar is the field name in the form)

const upload = multer({ storage: storage });
This creates an upload object using the storage strategy defined above.

You can now use it in your routes like this:
upload.single("avatar")  // for single file upload
upload.array("photos", 3)  // for multiple files (max 3 here)


----->
HTTPS ME bas S a encryption ki layer represent karti hai.

URL Uniform Resource Locator
A URL is a type of URI that tells you how to access a resource and where it is located.

It always includes:

Protocol (like http, ftp)

Location (domain name or IP)

Possibly path, query, port, etc.


URI Uniform Resource Identifier 
A URI is a generic term for anything that identifies a resourceâ€”either by location (where it is), by name (what it is), or both.
It is the umbrella term that includes both URL and URN.

URN
A URN is a URI that names a resource but does not tell how to locate it.

Itâ€™s often used for unique identifiers like ISBN, UUIDs, etc.


What are HTTP header?
HTTP headers are key-value pairs sent between the client and server in an HTTP request or response.

They are used to send metadataâ€”information about the request or response, not the actual data content.

In HTTP, headers contain metadata about:
Who is sending the request (browser info)
What type of response is accepted
Content types, encoding, authorization, caching, etc.

before 2012 X-prefix in http header

Category
request header -> from client
response header -> from server
representation headers -> encoding/compression
payload header -> data


Most commom headers
accept : application/json
user-agent : konsi si application se request aayi hai, browser konsi thi
authorization : 
content-type : image/pdf
cookie : kab tak log in rakhu
cahe-control : data kab expiry karu

Cors:
konsi credentials, methods allow hai like scarping disallow karni
 What is CORS?
CORS is a browser security mechanism.

It controls which domains are allowed to make cross-origin requests (i.e., different domain/port/protocol).

ðŸ”¸ Why it exists?
To prevent malicious sites from accessing sensitive APIs on your behalf (like scraping bank data or cookies).

ðŸ”¸ Example Headers in CORS:
Header	Purpose
Access-Control-Allow-Origin	Allow specific domain(s) to access resource (e.g., * or https://myapp.com).
Access-Control-Allow-Methods	Which HTTP methods are allowed (e.g., GET, POST, PUT).
Access-Control-Allow-Headers	Which request headers are allowed (e.g., Authorization, Content-Type).
Access-Control-Allow-Credentials	Allow sending cookies or credentials (true/false).


 Security Headers / Policies
Security headers help protect against common attacks like XSS, clickjacking, MIME sniffing, etc.

ðŸ”¹ Common Security Headers:
Header	Purpose
Strict-Transport-Security	Forces HTTPS for future requests.
Content-Security-Policy	Controls what content (scripts, styles, images) can be loaded.
X-Frame-Options	Prevents your site from being embedded in <iframe> (protects against clickjacking).
X-Content-Type-Options: nosniff	Prevents MIME-type sniffing (donâ€™t guess file type).
X-XSS-Protection	Enables browser's built-in XSS protection (legacy use).

HTTP METHODS
GET: Retieve a request
HEAD: no body only head in response
OPTIONS: which operations are available
TRACE: debug use, loopbacktrap ,konsi proxy se aa rahi hai
DELETE: remove
PUT:  replace
POST:  mostly add
PATCH: change a part 

HTTP STATUS CODE:
1** INFORMATION
2** SUCESS
3** REDIRECTION
4** CLIENT ERROR
5** SERVER ERROR

100 -> continue
102 -> processing
200 -> OK
201 -> created
202 -> accept
307 -> temporary redirect
308 -> permanent redirect
400 -> bad request
401 -> unauthorize
402 -> payment required
404 -> not found
500 -> internal server error
504 -> Gateway timeout

----> middleware in Express.js can add extra fields to the req (request) object so that the next middleware or route handler can use them.

ðŸ”¹ How it works
In Express, req, res, and next are objects passed to each middleware.

Since req is just a JavaScript object, you can add new properties to it.

This is often done to store user data, authentication info, custom metadata, etc.


ðŸ”¹ Common use cases
Authentication->

Middleware verifies JWT and attaches decoded user data to req.user.

File Upload->

Multer middleware adds req.file or req.files.

Request Metadata->

Add request ID, timestamps, correlation IDs for logging.

Shared Config->

Attach settings, API keys, or environment info for later middlewares.

âš ï¸ Things to keep in mind
Always call next() after modifying req, otherwise the request will hang.

Avoid overwriting existing properties like req.body unless intentional.

Since all middlewares share the same req object, changes persist down the chain.


const createdUser = await User.findById(user._id).select("-password -refreshToken")
ðŸ”¹ Why user._id is useful
When you create or fetch a user from MongoDB (via Mongoose), it automatically has a unique _id field (ObjectId).
This _id is super useful because:

Primary Key in MongoDB

Every document in MongoDB gets a unique _id when itâ€™s created.

Itâ€™s automatically indexed, so lookups like findById() are very fast.

Direct and Efficient Queries

findById(user._id) is faster and cleaner than searching with another field like username or email.

Uniquely Identifies the User

Even if a user changes their email, username, or other info, _id stays constant.

Relationships & References

_id is used in other collections for referencing (e.g., createdBy in todos).

This avoids storing large objects â€” just store the _id.

ðŸ”¹ Why .select("-password -refreshToken") is used
.select() lets you choose which fields to include or exclude in the query result.

"-password" â†’ exclude the password field

"-refreshToken" â†’ exclude the refresh token field

Why exclude?

Security: Prevents sending sensitive data to the client.

Efficiency: Smaller response size.


----------------->

1ï¸âƒ£ Access Token

Purpose: Quickly verify a user's identity for API requests.

Short-lived (e.g., 15 minutes â€“ 1 hour).

Stored on the client side (usually in memory or a secure cookie).

Not saved in the DB because:

They expire quickly.

Theyâ€™re stateless â€” the server just validates them using a secret/public key.

No need to persist them (less DB overhead).

2ï¸âƒ£ Refresh Token

Purpose: Issue a new access token without making the user log in again.

Long-lived (days/weeks/months).

Stored both:

On client (in a secure cookie or storage).

On server/database (linked to the user).

Why save in DB?

To validate authenticity â€” if a refresh token is stolen and you detect it, you can delete it from DB to instantly invalidate it.

For logout functionality â€” deleting the token from DB ensures it canâ€™t be reused.

Supports multi-device tracking â€” you can save multiple refresh tokens per user to know from which devices they're logged in.

3ï¸âƒ£ Flow

User logs in â†’ Server creates accessToken + refreshToken.

Access token is used for normal API calls.

When access token expires â†’ Client sends refresh token to get a new access token.

Server checks refresh token in DB:

If valid â†’ generate new access token.

If not found or expired â†’ force login again.

4ï¸âƒ£ Why only refresh token is saved

Access token is short-lived â†’ storing is unnecessary.

Refresh token is long-lived and must be tracked for:

Revocation (logout, device removal)

Security (detect theft, compromise)

Multi-device session management

[1] User Logs In
       |
       |--> Server verifies credentials
       |
       |--> Server generates:
       |       Access Token (short life, e.g. 15 min)
       |       Refresh Token (long life, e.g. 7 days)
       |
       |--> Sends both to client
               - Access Token â†’ memory / HTTP-only cookie
               - Refresh Token â†’ HTTP-only cookie / secure storage

---------------------------------------------------------------

[2] Client Makes API Request
       |
       |--> Attaches Access Token in Authorization header
       |
       |--> Server verifies Access Token signature + expiry
       |
       |--> If valid â†’ proceed with request
       |--> If expired â†’ go to step 3

---------------------------------------------------------------

[3] Access Token Expired â†’ Use Refresh Token
       |
       |--> Client sends Refresh Token to /refresh-token endpoint
       |
       |--> Server checks:
               - Refresh Token exists in DB
               - Not expired / revoked
       |
       |--> If valid:
               - Generate new Access Token
               - (Optionally) Generate new Refresh Token
       |
       |--> Send new tokens to client
       |
       |--> Client retries the original API request

---------------------------------------------------------------

[4] User Logs Out
       |
       |--> Server deletes Refresh Token from DB
       |--> Access Token naturally expires soon


Key points in the flow:

Access Token = speed & efficiency (used every request).

Refresh Token = stability & security (keeps session alive).

If a refresh token is stolen â†’ attacker can keep generating new access tokens â†’ why refresh tokens must be stored securely and can be revoked.
